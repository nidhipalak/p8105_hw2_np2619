p8105\_hw2\_np2619
================
Nidhi Patel
9/28/2020

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

###### Clean up Mr. Trash Wheel

``` r
trash = 
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "Mr. Trash Wheel",
    range = "A2:N406") %>%
janitor::clean_names() %>%
drop_na(dumpster) %>%
mutate(
  sports_balls = round(sports_balls),
  sports_balls = as.integer(sports_balls)
  )
```

###### Clean up precipitation 2017 and 2018

Import datasets + clean a bit

``` r
precip17 = 
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2017 Precipitation",
        range = "A2:B14") %>%
janitor::clean_names() %>% 
mutate(year = "2017") %>% 
  mutate(month = month.name)

precip18 = 
  read_excel(
    "./Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2018 Precipitation",
    range = "A2:B14") %>%
janitor::clean_names() %>% 
mutate(year = "2018") %>% 
  mutate(month = month.name)
```

###### Join datasets

``` r
precipitation = 
  bind_rows(precip17, precip18)
```

The Mr. Trash Wheel data has 344 observations after cleaned. The median
number of sports balls in a dumpster in 2017 is 8.

The precipitation data set looks at amount of rainfall in inches per
month for 2017 and 2018. In 2017, the average precipitation is 2.7441667
with the min of 0 and max of 7.09. In 2018, the average monthly
precipitation is 5.8608333 with a min of 0.94 and max of 10.47. For the
two years the average precipitation is 4.3025 with a total of 24
observations. The total precipitation in 2018 is 70.33.

## Problem 2

``` r
transit = 
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = as.logical(recode(entry, "YES" = "TRUE", "NO" = "FALSE"))) %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route",
    values_to = "rt_name"
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

First, to tidy this data, I cleaned names and converted the character
‘entry’ vector to logical. This dataset had many routes that can be
combined into one column, but first all the routes have to match and
route8-route11 were converted to characters to match route1-route7. I
used `pivot_longer` to tidy the data for easier analysis.
